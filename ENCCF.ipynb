{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcyb+TZrJlaJs85p40ymGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arslane101/PFE/blob/main/ENCCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import calendar\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "from os import cpu_count\n",
        "import pickle as pk\n",
        "from math import nan\n",
        "from re import I\n",
        "from unittest import result\n",
        "import random\n",
        "from keras.engine.input_layer import Input\n",
        "from datetime import date,datetime,timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from yaml import load\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "i4RcxpjHA7f3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *"
      ],
      "metadata": {
        "id": "adPDYCIufVOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip"
      ],
      "metadata": {
        "id": "gxsgSKApCA0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ChargerDataset(ratings,th):\n",
        "    for i in range(ratings.shape[0]):\n",
        "        if pd.isnull(ratings['rating'][i]) :\n",
        "            ratings.loc[i,'rating'] = int(0)\n",
        "        if int(ratings['rating'][i]) >= int(th):\n",
        "            ratings.loc[i,'rating']= int(1)\n",
        "        else: ratings.loc[i,'rating']=int(0) \n",
        "def ListRelevant(matrix,n_items,ind):\n",
        "    relevants = []\n",
        "    for i in range(n_items):\n",
        "        if(matrix.iloc[ind,i]==1):\n",
        "            relevants.append(i)\n",
        "    return relevants   \n",
        "def ListRel(array):\n",
        "    relevants = []\n",
        "    for i in range(len(array)):\n",
        "        if(array[i]==1):\n",
        "            relevants.append(i)\n",
        "    return relevants \n",
        "def ListSpecRel(array):\n",
        "    relevants = []\n",
        "    for i in range(len(array)):\n",
        "        if(array[i]==1):\n",
        "            relevants.append(list_movies[i])\n",
        "    return relevants \n",
        "def Relevant(matrix):\n",
        "    relevants = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        for j in range(matrix.shape[1]):\n",
        "            if(matrix.iloc[i,j]==1) and j not in relevants:\n",
        "              relevants.append(j)\n",
        "    return relevants   \n",
        "def Commons(subset,subsets):\n",
        "    count = 0\n",
        "    for i in range(len(subsets)):\n",
        "        if(len(set(subset).intersection(subsets[i]))!=0):\n",
        "            count+=1\n",
        "    return count\n",
        "def RandomSubsets(n_items,nb):\n",
        "    subsets = list()\n",
        "    subset = list(range(0,n_items))\n",
        "    for i in range(nb):\n",
        "        sub = random.sample(subset,int(n_items/nb))\n",
        "        subset = list(set(subset)-set(sub))\n",
        "        subsets.append(sub)\n",
        "    return subsets\n",
        "def where(arr,nb):\n",
        "    for i in range(len(arr)):\n",
        "        if(arr[i]==nb):\n",
        "            return i\n",
        "def EnsembleSamplesTraining(nb):\n",
        "  itemslist = np.loadtxt(\"Subsets.txt\")\n",
        "  nbrel= ratings[ratings[\"rating\"] == 1.0].shape[0]\n",
        "  k=0\n",
        "  Input = np.zeros((nbrel,n_items),dtype=np.int8)\n",
        "  Target = np.zeros((nbrel),dtype=np.int16)\n",
        "  for i in range(pivot.shape[0]):\n",
        "    for j in  ListRelevant(pivot,n_items,i):\n",
        "        Input[k] = np.array(pivot.iloc[i,:],copy=True)\n",
        "        Input[k,j]=0\n",
        "        Target[k]=j\n",
        "        k+=1\n",
        "  print(Input.shape) \n",
        "  print(Target.shape)     \n",
        "  #Splitting the Data\n",
        "  i=0\n",
        "  for  i in range(nb):\n",
        "   if(nb != 1 ) :\n",
        "     itembis = itemslist[i]\n",
        "   else : itembis = itemslist\n",
        "   count = 0\n",
        "   for j in range(len(Target)):\n",
        "        if(Target[j] in itembis):\n",
        "                count+=1\n",
        "   InputT = np.zeros((count,n_items))\n",
        "   TargetT= np.zeros((count))\n",
        "   k=0\n",
        "   j=0       \n",
        "   while j<len(InputT) or k<count:\n",
        "        if(Target[j] in itembis):\n",
        "            InputT[k]=Input[j,:]\n",
        "            TargetT[k]=where(itembis,Target[j])\n",
        "            k+=1\n",
        "        j+=1\n",
        "   InputTrain,InputTest,TargetTrain,TargetTest = train_test_split(InputT,TargetT,test_size=0.2,random_state=28)\n",
        "   np.savetxt(\"InputTe\"+str(i)+\".txt\",InputTest.astype(int),fmt='%d')\n",
        "   np.savetxt(\"TargetTe\"+str(i)+\".txt\",TargetTest.astype(int),fmt='%d')\n",
        "   np.savetxt(\"InputTr\"+str(i)+\".txt\",InputTrain.astype(int),fmt='%d')\n",
        "   np.savetxt(\"TargetTr\"+str(i)+\".txt\",TargetTrain.astype(int),fmt='%d')\n",
        "def EnsembleSamplesTesting(nb):\n",
        "    itemslist = np.loadtxt(\"Subsets.txt\")\n",
        "    values = list()\n",
        "    itemlist = np.concatenate(itemslist)\n",
        "    shape = itemslist.shape[0]\n",
        "    for i in range(shape):\n",
        "        model = load_model(str(i))\n",
        "        testUser = np.array(pivot.iloc[nb,:],copy=True)\n",
        "        testUser = testUser.reshape(1,testUser.shape[0])\n",
        "        results = model.predict(testUser)\n",
        "        results = results/itemslist.shape[1]\n",
        "        values.append(results)\n",
        "    results = np.concatenate(np.asarray(values))\n",
        "    results = np.argsort(results.reshape(itemlist.shape[0]))[::-1] \n",
        "    for i in range(results.shape[0]):\n",
        "        results[i] = int(itemlist[results[i]]) \n",
        "    return results\n",
        "def EnsembleLearning(nb):\n",
        " itembis = np.loadtxt(\"Subsets.txt\")\n",
        " i=0\n",
        " for i in range(nb):\n",
        "  if nb != 1 :\n",
        "    liste = itembis[i]\n",
        "  else : liste = itembis\n",
        "  InputTest = np.loadtxt(\"InputTe\"+str(i)+\".txt\")\n",
        "  TargetTest = np.loadtxt(\"TargetTe\"+str(i)+\".txt\")\n",
        "  InputTrain =  np.loadtxt(\"InputTr\"+str(i)+\".txt\")\n",
        "  TargetTrain = np.loadtxt(\"TargetTr\"+str(i)+\".txt\")\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=InputTrain.shape[1]))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(Dense(len(liste),activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  model.fit(InputTrain,TargetTrain,validation_data=(InputTest,TargetTest),epochs=80,batch_size=150)\n",
        "  model.save(format(i))\n",
        "def MostRatedMovies(ratings,min):\n",
        "    ratings = ratings.groupby(['movieId'])[['rating']].mean()\n",
        "    ratings = ratings[ratings[\"rating\"] >= min]\n",
        "    return ratings.index.unique().tolist()\n",
        "def FilterContext(results,movies):\n",
        "    movie = list()\n",
        "    for mov in movies:\n",
        "        movie.append(where(list_movies,mov))\n",
        "    result = list()\n",
        "    for elt in results:\n",
        "        if( elt in movie):\n",
        "            result.append(elt)\n",
        "    return result\n",
        "def EnsembleSamples(nb):\n",
        "    itemslist = np.loadtxt(\"Subsets.txt\")\n",
        "    itemlist = np.concatenate(itemslist)\n",
        "    values = list()\n",
        "    for i in range(itemslist.shape[0]):\n",
        "        model = load_model(str(i))\n",
        "        testUser = np.array(pivot.iloc[nb,:],copy=True)\n",
        "        testUser = testUser.reshape(1,testUser.shape[0])\n",
        "        results = model.predict(testUser)\n",
        "        values.append(results)\n",
        "    results = np.concatenate(np.asarray(values))\n",
        "    results = results.reshape(itemlist.shape[0])\n",
        "    result = pd.DataFrame(columns=['movieId','probability'])\n",
        "    for i in range(results.shape[0]):\n",
        "        result.loc[len(result.index)]=[list_movies[int(itemlist[i])],results[i]]\n",
        "    return result"
      ],
      "metadata": {
        "id": "r9PawoeMBmuO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv(\"ratings.csv\",delimiter=\";\",parse_dates=['timestamp'],infer_datetime_format=True)\n",
        "print(ratings.shape)\n"
      ],
      "metadata": {
        "id": "7oIk8KLCE30j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChargerDataset(ratings,4)"
      ],
      "metadata": {
        "id": "RycC8cDSeEYm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot = ratings.pivot_table(index=['userId'],columns=['movieId'],values='rating',fill_value=0)\n",
        "n_users = pivot.index.unique().shape[0]\n",
        "n_items = pivot.columns.unique().shape[0]\n",
        "list_movies = pivot.columns.unique().tolist()\n",
        "list_users = pivot.index.unique().tolist()\n",
        "\n",
        "subsets = RandomSubsets(n_items,2)\n",
        "np.savetxt(\"Subsets.txt\",np.array(subsets).astype(int),fmt='%d')\n"
      ],
      "metadata": {
        "id": "lbGmyvRyB4lu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pivot.shape)\n"
      ],
      "metadata": {
        "id": "Aj3XW7AeeVyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66505d27-8d02-495d-c716-04967f5b5215"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(943, 1682)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EnsembleSamplesTraining(2)"
      ],
      "metadata": {
        "id": "CGgq-7rfS_Rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd79b5f6-9890-4cef-867d-045318bab0e3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55375, 1682)\n",
            "(55375,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EnsembleLearning(2)"
      ],
      "metadata": {
        "id": "MC2aKlEbOCwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j=0\n",
        "n= 96\n",
        "totalprec = list()\n",
        "totalrec = list()\n",
        "for j in range(40):\n",
        " i=1\n",
        " recalls = list()\n",
        " precisions = list()\n",
        " recalls.append(j)\n",
        " precisions.append(j)\n",
        " testUser = np.array(pivot.iloc[j,:],copy=True)\n",
        " rev  = ListRel(testUser)\n",
        " results = EnsembleSamplesTesting(j)\n",
        " if(len(rev)>50):\n",
        "  recalls.append(len(rev))\n",
        "  precisions.append(len(rev))    \n",
        "  while(i<n):   \n",
        "    hr=0\n",
        "    temp = results[:i] \n",
        "    for k in range(len(temp)):\n",
        "         if  temp[k] in rev:\n",
        "          hr+=1\n",
        "    prec = (hr)/i\n",
        "    rec =  (hr)/len(rev) \n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    i+=5\n",
        "  totalprec.append(np.asarray(precisions))\n",
        "  totalrec.append(np.asarray(recalls))\n",
        "np.savetxt(\"AllPrecisions.txt\", np.vstack(totalprec).astype(float),fmt='%.2f')\n",
        "np.savetxt(\"AllRecalls.txt\",np.vstack(totalrec).astype(float),fmt='%.2f')"
      ],
      "metadata": {
        "id": "9U18b0PlhOro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a0a23-fc21-44e4-c22f-f1bf2ebc5602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        }
      ]
    }
  ]
}